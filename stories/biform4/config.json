{
  "architectures": [
    "Transformer"
  ],
  "attn_dropout": 0.0,
  "bilinear": true,
  "d_head": 64,
  "d_hidden": 256,
  "d_model": 128,
  "embed_dropout": 0.0,
  "mlp_dropout": 0.0,
  "n_ctx": 212,
  "n_head": 4,
  "n_layer": 4,
  "n_vocab": 2048,
  "norm": "rms",
  "resid_dropout": 0.0,
  "torch_dtype": "float32",
  "transformers_version": "4.39.0"
}
